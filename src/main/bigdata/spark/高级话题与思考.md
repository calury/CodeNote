## 高级话题与思考

### 配置
- 1.几个环境变量
```
export HADOOP_CONF_DIR=/path/to/hadoop/etc/hadoop
export YARN_CONF_DIR=/path/to/hadoop/etc/hadoop
export SPARK_LOG_DIR=/path/to/spark/log
export SPARK_WORKER_DIR=/path/to/spark
```

#### TODO
- 为什么要有partition的概念，分区的设计能带来什么好处，HDFS、hive、spark这些都有吗，除了这些，还有哪些也有？
> 分区与并发，并行有关系
- spark将一个作业转换为一个多步的DAG，DAG越复杂，spark相比MR的性能提升越明显，为什么？