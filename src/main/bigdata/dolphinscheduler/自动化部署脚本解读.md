## 自动化部署脚本

install.sh
```bash
#!/bin/sh

workDir=`dirname $0`    # $0表示install.sh的路径文件名。dirname $0 可以拿到该文件所在的目录 比如/opt/softwares/escheduler-1.1.0-backend
workDir=`cd ${workDir};pwd` # 这一步是为了拿到绝对路径。因为我们在/opt/softwares/escheduler-1.1.0-backend这个目录下执行 sh install.sh的话workDir=.需要转为绝对路径

# 检查运行平台
txt=""
if [[ "$OSTYPE" == "darwin"* ]]; then
    # Mac OSX
    txt="''"
elif [[ "$OSTYPE" == "linux-gnu" ]]; then
    # linux
    txt=""
...
fi

# source用于执行文件的内容
source ${workDir}/conf/config/run_config.conf # 组件分布配置  
# masters=ark0,ark1
# workers=ark2,ark3,ark4
# alertServer=ark3
# apiServers=ark1
source ${workDir}/conf/config/install_config.conf # 部署的配置
# installPath=/data1_1T/escheduler  # 部署安装的位置
# deployUser=escheduler             # 执行部署的用户
# ips=ark0,ark1,ark2,ark3,ark4      # 部署的主机名


# mysql配置
# mysql 地址,端口
mysqlHost="192.168.xx.xx:3306"

# mysql 数据库名称
mysqlDb="escheduler"

# mysql 用户名
mysqlUserName="xx"

# mysql 密码
# 注意：如果有特殊字符，请用 \ 转移符进行转移
mysqlPassword="xx"

# conf/config/install_config.conf配置
# 注意：安装路径,不要当前路径(pwd)一样
installPath="/data1_1T/escheduler"

# 部署用户
# 注意：部署用户需要有sudo权限及操作hdfs的权限，如果开启hdfs，根目录需要自行创建
deployUser="escheduler" # 这个地方其实就会覆盖上面用source ${workDir}/conf/config/install_config.conf得到的deployUser变量

# zk集群
zkQuorum="192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181"

# 安装hosts
# 注意：安装调度的机器hostname列表，如果是伪分布式，则只需写一个伪分布式hostname即可
ips="ark0,ark1,ark2,ark3,ark4" 

# conf/config/run_config.conf配置
# 运行Master的机器
# 注意：部署master的机器hostname列表
masters="ark0,ark1"

# 运行Worker的机器
# 注意：部署worker的机器hostname列表
workers="ark2,ark3,ark4"

# 运行Alert的机器
# 注意：部署alert server的机器hostname列表
alertServer="ark3"

# 运行Api的机器
# 注意：部署api server的机器hostname列表
apiServers="ark1"

# alert配置
# 邮件协议
mailProtocol="SMTP"

# 邮件服务host
mailServerHost="smtp.exmail.qq.com"

# 邮件服务端口
mailServerPort="25"

# 发送人
mailSender="xxxxxxxxxx"

# 发送人密码
mailPassword="xxxxxxxxxx"

# TLS邮件协议支持
starttlsEnable="false"

# SSL邮件协议支持
# 注意：默认开启的是SSL协议，TLS和SSL只能有一个处于true状态
sslEnable="true"

# 下载Excel路径
xlsFilePath="/tmp/xls"

# 企业微信企业ID配置
enterpriseWechatCorpId="xxxxxxxxxx"

# 企业微信应用Secret配置
enterpriseWechatSecret="xxxxxxxxxx"

# 企业微信应用AgentId配置
enterpriseWechatAgentId="xxxxxxxxxx"

# 企业微信用户配置,多个用户以,分割
enterpriseWechatUsers="xxxxx,xxxxx"


#是否启动监控自启动脚本
monitorServerState="false"

# 资源中心上传选择存储方式：HDFS,S3,NONE
resUploadStartupType="NONE"

# 如果resUploadStartupType为HDFS，defaultFS写namenode地址，支持HA,需要将core-site.xml和hdfs-site.xml放到conf目录下
# 如果是S3，则写S3地址，比如说：s3a://escheduler，注意，一定要创建根目录/escheduler
defaultFS="hdfs://mycluster:8020"

# 如果配置了S3，则需要有以下配置
s3Endpoint="http://192.168.xx.xx:9010"
s3AccessKey="xxxxxxxxxx"
s3SecretKey="xxxxxxxxxx"

# resourcemanager HA配置，如果是单resourcemanager,这里为yarnHaIps=""
yarnHaIps="192.168.xx.xx,192.168.xx.xx"

# 如果是单 resourcemanager,只需要配置一个主机名称,如果是resourcemanager HA,则默认配置就好
singleYarnIp="ark1"

# hdfs根路径，根路径的owner必须是部署用户。1.1.0之前版本不会自动创建hdfs根目录，需要自行创建
hdfsPath="/escheduler"

# 拥有在hdfs根路径/下创建目录权限的用户
# 注意：如果开启了kerberos，则直接hdfsRootUser=""，就可以
hdfsRootUser="hdfs"

# common 配置
# 程序路径
programPath="/tmp/escheduler"

#下载路径
downloadPath="/tmp/escheduler/download"

# 任务执行路径
execPath="/tmp/escheduler/exec"

# SHELL环境变量路径
# 这里面是需要的环境变量，比如有：export JAVA_HOME=/opt/soft/java；export HIVE_HOME=/opt/soft/hive，也是需要更改的
shellEnvPath="$installPath/conf/env/.escheduler_env.sh" 
                                                                          	
# 资源文件的后缀
resSuffixs="txt,log,sh,conf,cfg,py,java,sql,hql,xml"

# 开发状态,如果是true,对于SHELL脚本可以在execPath目录下查看封装后的SHELL脚本,如果是false则执行完成直接删除
devState="true"

# kerberos 配置
# kerberos 是否启动
kerberosStartUp="false"

# kdc krb5 配置文件路径
krb5ConfPath="$installPath/conf/krb5.conf"

# keytab 用户名
keytabUserName="hdfs-mycluster@ESZ.COM"

# 用户 keytab路径
keytabPath="$installPath/conf/hdfs.headless.keytab"

# zk 配置
# zk根目录
zkRoot="/escheduler"

# 用来记录挂掉机器的zk目录
zkDeadServers="/escheduler/dead-servers"

# masters目录
zkMasters="/escheduler/masters"

# workers目录
zkWorkers="/escheduler/workers"

# zk master分布式锁
mastersLock="/escheduler/lock/masters"

# zk worker分布式锁
workersLock="/escheduler/lock/workers"

# zk master容错分布式锁
mastersFailover="/escheduler/lock/failover/masters"

# zk worker容错分布式锁
workersFailover="/escheduler/lock/failover/workers"

# zk master启动容错分布式锁
mastersStartupFailover="/escheduler/lock/failover/startup-masters"

# zk session 超时
zkSessionTimeout="300"

# zk 连接超时
zkConnectionTimeout="300"

# zk 重试间隔
zkRetrySleep="100"

# zk重试最大次数
zkRetryMaxtime="5"


# master 配置
# master执行线程最大数,流程实例的最大并行度
masterExecThreads="100"

# master任务执行线程最大数,每一个流程实例的最大并行度
masterExecTaskNum="20"

# master心跳间隔
masterHeartbeatInterval="10"

# master任务提交重试次数
masterTaskCommitRetryTimes="5"

# master任务提交重试时间间隔
masterTaskCommitInterval="100"

# master最大cpu平均负载,用来判断master是否还有执行能力
masterMaxCpuLoadAvg="10"

# master预留内存,用来判断master是否还有执行能力
masterReservedMemory="1"


# worker 配置
# worker执行线程
workerExecThreads="100"

# worker心跳间隔
workerHeartbeatInterval="10"

# worker一次抓取任务数
workerFetchTaskNum="3"

# worker最大cpu平均负载,用来判断worker是否还有执行能力,保持系统默认，默认为cpu核数的2倍，当负载达到2倍时，
#workerMaxCupLoadAvg="10"

# worker预留内存,用来判断master是否还有执行能力
workerReservedMemory="1"

# api 配置
# api 服务端口
apiServerPort="12345"

# api session 超时
apiServerSessionTimeout="7200"

# api 上下文路径
apiServerContextPath="/escheduler/"

# spring 最大文件大小
springMaxFileSize="1024MB"

# spring 最大请求文件大小
springMaxRequestSize="1024MB"

# api 最大post请求大小
apiMaxHttpPostSize="5000000"

# 1,替换和生产文件，把instal.sh脚本配置好的变量值更新回配置文件中或者生成新的文件，主要有
# conf/dao/data_source.properties 数据库连接信息
# conf/quartz.properties quartz配置连接信息
# conf/common/hadoop/hadoop.properties hadoop相关配置信息
# conf/common/common.properties
# conf/zookeeper.properties
# conf/master.properties
# worker.properties
# conf/application.properties
# conf/alert.properties
# conf/config/install_config.conf
# conf/config/run_config.conf

echo "1,替换文件"
sed -i ${txt} "s#spring.datasource.url.*#spring.datasource.url=jdbc:mysql://${mysqlHost}/${mysqlDb}?characterEncoding=UTF-8#g" conf/dao/data_source.properties
...

# 2,创建目录
echo "2,创建目录"

if [ ! -d $installPath ];then # -d 用在if语句中，表示是否是目录。在这里如果不存在目录就新建并授权
  sudo mkdir -p $installPath
  sudo chown -R $deployUser:$deployUser $installPath
fi

hostsArr=(${ips//,/ }) # 语法${parameter//pattern/string}表示对parameter用pattern去匹配，匹配到的内容用string替换。
# 这里是把 s00,s01,s02替换成s00 s01 s02 之后hostsArr=(s00 s01 s02)得到一个数组
# 下面这一行是遍历数组。也就是对每台主机上执行创建目录的动作。使用ssh $host的命令 
for host in ${hostsArr[@]} # []表示索引 [0]表示第一个 [@]表示所有，相当于python的 for i in list[:]
do

# 如果programPath不存在,则创建
if ! ssh $host test -e $programPath; then # test –e File 判断文件是否存在
  ssh $host "sudo mkdir -p $programPath;sudo chown -R $deployUser:$deployUser $programPath"
fi

# 如果downloadPath不存在,则创建
if ! ssh $host test -e $downloadPath; then
  ssh $host "sudo mkdir -p $downloadPath;sudo chown -R $deployUser:$deployUser $downloadPath"
fi

# 如果$execPath不存在,则创建
if ! ssh $host test -e $execPath; then
  ssh $host "sudo mkdir -p $execPath; sudo chown -R $deployUser:$deployUser $execPath"
fi

# 如果$xlsFilePath不存在,则创建
if ! ssh $host test -e $xlsFilePath; then
  ssh $host "sudo mkdir -p $xlsFilePath; sudo chown -R $deployUser:$deployUser $xlsFilePath"
fi

done


# 3,停止服务
echo "3,停止服务"
sh ${workDir}/script/stop_all.sh

# 4,删除zk节点 使用python脚本
echo "4,删除zk节点"
sleep 1
python ${workDir}/script/del_zk_node.py $zkQuorum $zkRoot

# 5,scp资源 把部署文件分发到各个主机上 scp -r /xxx/escheduler $host/xxx
echo "5,scp资源"
sh ${workDir}/script/scp_hosts.sh
if [ $? -eq 0 ] # $? 表示最后运行的命令的结束的代码（返回值）
then
	echo 'scp拷贝完成'
else
	echo 'sc 拷贝失败退出'
	exit -1
fi

# 6,启动
echo "6,启动"
sh ${workDir}/script/start_all.sh

# 7,启动监控自启动脚本
monitor_pid=${workDir}/monitor_server.pid
if [ "true" = $monitorServerState ];then
        if [ -f $monitor_pid ]; then
                TARGET_PID=`cat $monitor_pid`
                if kill -0 $TARGET_PID > /dev/null 2>&1; then
                        echo "monitor server running as process ${TARGET_PID}.Stopping"
                        kill $TARGET_PID
                        sleep 5
                        if kill -0 $TARGET_PID > /dev/null 2>&1; then
                                echo "monitor server did not stop gracefully after 5 seconds: killing with kill -9"
                                kill -9 $TARGET_PID
                        fi
                else
                        echo "no monitor server to stop"
                fi
                echo "monitor server running as process ${TARGET_PID}.Stopped success"
                rm -f $monitor_pid
        fi
        nohup python -u ${workDir}/script/monitor_server.py $installPath $zkQuorum $zkMasters $zkWorkers > ${workDir}/monitor_server.log 2>&1 &
        echo $! > $monitor_pid
        echo "start monitor server success as process `cat $monitor_pid`"

fi
```


通读完部署脚本之后，我们可以发现，在部署之后，如果需要修改参数，我们需要到部署目录下去修改
```
# 进入所有配置文件所在的路径
cd /data1_1T/escheduler/
# 一些基础信息配置
vim conf/dao/data_source.properties 数据库连接信息
vim conf/quartz.properties quartz配置连接信息
vim conf/common/hadoop/hadoop.properties hadoop相关配置信息
vim conf/common/common.properties
vim conf/zookeeper.properties

# 组件配置
vim conf/master.properties
vim conf/worker.properties
vim conf/alert.properties

# springboot 配置
vim conf/application.properties

vim conf/config/install_config.conf
vim conf/config/run_config.conf
```
