# 1，模块功能测试

模块分别抽象为**安全中心、数据源中心、资源中心、首页和监控中心**

## 安全中心

### 租户管理

- 创建租户

  **验证点：看是否在HDFS上创建租户目录**

- 编辑租户

- 删除租户

  **验证点：只有租户下面的资源是空的才能删除**

### 用户管理

验证点：

**1，默认管理员登录进来是有管理员用户的，但是管理员没有关联租户，所以如果要使用管理员进行任务提交，必须得关联一个租户**

**2，或者保存流程定义的时候设置一个租户**

- 创建用户

  验证点：**如果用户设置了对象，会将租户身上的队列冲掉，仅对Hadoop和Spark任务生效**

- 编辑

- 删除

- 授权

  1，项目授权

  2，资源授权

  3，数据源授权

  4，UDF函数授权

  验证点：**管理员对普通用户授完权限之后，普通用户能否正确使用，而且对于授予的权限，只有管理员和所有者（创建者）才可以删除**

### 队列管理

- 创建队列

### Worker分组管理

- 创建Worker分组
- 编辑
- 删除
- **流程定义启动指定Worker分组**
- **任务实例指定Worker分组**

### 令牌管理

- 创建令牌

- 编辑

- 删除

- **生成的有效期的Token**

  验证点：**通过 escheduler-api test下 cn.escheduler.api 包下的HttpClientTest进行验证是否能正常请求及Token的有效期**



## 数据源中心

- 创建各种数据源

  验证点：**对于Hive和Spark同时需要验证Kerberos**

- 编辑

- 删除

## 资源中心

### 文件管理

**以下需要分别的验证 HDFS 和 S3 两个分布式文件系统下的情况**

- 在线创建文件

- 上传文件

  验证点：**1，设置上传文件的最大Size，并测试两个极端情况**

  ​		**2，需要验证资源是否已经正确上传（数据库和分布式文件系统）**

- 编辑

- 重命名

- 下载

- 删除

### UDF管理

#### 资源管理

- 上传UDF资源

  验证点：**需要验证资源是否已经正确上传（数据库和分布式文件系统）**

- 重命名

- 下载

- 删除

#### 函数管理

- 创建UDF函数

  验证点：**创建UDF函数并在Hive SQL任务中进行验证**

- 编辑

- 删除

## 首页

**项目首页和首页**

验证点：**1，任务状态统计 2，流程状态统计 3，流程定义统计**（是否和数据库中的状态是匹配的）



## 项目管理

### 项目

- 创建项目

- 编辑项目

- 删除项目

  验证点：**删除项目的时候，项目下面是没有流程定义的**

- 项目中流程定义个数，**运行**流程实例个数

### 工作流定义

#### 创建工作流

通用测试：

一，禁止运行

验证点：**设置了 禁止运行 的任务，在流程启动的时候会把其关联的先断掉**

二，任务优先级

验证点：**同一个流程实例的并行任务，优先级高的优先运行**

三，失败重试次数，任务重试间隔

验证点：**测试任务失败之后，任务重新调度的时间间隔**

四，超时告警

验证点：**1，超时告警，邮件通知**

​		**2，超时失败，查看任务状**态

五，**自定义参数（这个需要和具体的Task关联测试）**

**参数分为局部参数和全局参数，局部参数可以引用全局参数的变量，此时全局参数可以是常量，也可以是变量**

**内置系统参数：**

- ${system.biz.date}：日常调度实例定时的定时时间前一天，格式为 yyyyMMdd
- ${system.biz.curdate}：日常调度实例定时的定时时间，格式为 yyyyMMdd
- ${system.datetime}：日常调度实例定时的定时时间，格式为 yyyyMMddHHmmss

**时间自定义参数：**

- 后 N 年：$[add_months(yyyyMMdd,12*N)]
- 前 N 年：$[add_months(yyyyMMdd,-12*N)]
- 后 N 月：$[add_months(yyyyMMdd,N)]
- 前 N 月：$[add_months(yyyyMMdd,-N)]
- 后 N 周：$[yyyyMMdd+7*N]
- 前 N 周：$[yyyyMMdd-7*N]
- 后 N 天：$[yyyyMMdd+N]
- 前 N 天：$[yyyyMMdd-N]
- 后 N 小时：$[HHmmss+N/24]
- 前 N 小时：$[HHmmss-N/24]
- 后 N 分钟：$[HHmmss+N/24/60]
- 前 N 分钟：$[HHmmss-N/24/60]

##### SHELL

测试点：1，直接在 **脚本** 框中写SHELL脚本运行测试，并查看任务运行日志信息

​	       2，将脚本上传到资源中心，在 **脚本** 框中直接调用脚本，并查看任务运行日志信息

​	       3，自定义参数测试（包含局部参数和全局参数）

#####  SUB_PROCESS

测试点：1，**主流程嵌套子流程测试**

#####  PROCEDURE

测试点：1，选择不同数据源类型及地址，测试存储过程

​	        2，测试自定义参数及测试存储过程的IN、OUT两种传参类型

#####  SQL

测试点：1，选择不同数据源类型及地址，测试SQL语句

​		2，测试SQL类型，查询和非查询

​		3，测试邮件发送形式，表格，附件，表格和附件三种形式

​		4，主题，支持参数传递测试

​		5，前置SQL和后置SQL测试

​		6，自定义参数测试（包含局部参数和全局参数）

#####  Flink

测试点：1，测试Flink on YARN模式

​	       2，测试命令行参数

​	       3，测试其他参数

​	       4，测试Python Flink

##### Spark

测试点：1，测试Spark on YARN，client，local 模式

​	        2，测试命令行参数

​	       3，测试其他参数

​	      4，测试Python Spark

#####  MR

测试点：1，测试MR on YARN 模式

​	       2，测试命令行参数

​	       3，测试其他参数

​	       4，测试Python MR



#####  PYTHON

测试点：1，直接在 **脚本** 框中写 Python 脚本运行测试，并查看任务运行日志信息

​	       2，将脚本上传到资源中心，在 **脚本** 框中直接调用脚本，并查看任务运行日志信息

​	       3，自定义参数测试（包含局部参数和全局参数）

#####  DEPENDENT

测试点：1，对区间（月、周、日、时）的偏移量（前xxx）测试

​	       2，条件 **且和或** 测试



#### 导入导出工作流

验证点：**先导出工作流再导入该工作流，启动，查看是否能正常运行**

#### 运行

- 失败策略

  验证点：**测试对于分支并行运行任务失败继续和失败结束两种效果，测试失败结束，是否Kill并行任务**

- 通知策略

  验证点：验证流程实例的各种通知策略

- 流程优先级

  验证点：**同时提交到ZK队列的两个不同等级的流程，验证其运行优先级**

- 通知组

  验证点：**安全中心建立用户组，运行选择通知组验证**

- 收件人和抄送人

- 补数：**（使用系统参数进行验证）**

  验证点：1，串行执行

  ​	        2，并行执行

  ​		3，指定天补数和区间补数

#### 定时

- 起止时间

  验证点：**测试在选择的时间范围内 ，定时有效**

- 定时

  验证点：**设置定时，执行时间，查看定时未来执行的时间**

- **其他参数和运行参数类似，参考运行参数进行测试**

#### 上/下线

验证点：1，**只有下线才能编辑工作流**

​		2，**如果下线的流程定义上有定时，则会删除定时，并让定时下线**

#### 树图形

### 工作流实例

- 重跑

  验证点：**流程重跑会对流程的系统参数固化下来，这个需要测试**

- 暂停/恢复暂停

  验证点：**对正在运行的流程暂停，只能暂停一下一个任务节点。恢复暂停，对暂停的节点进行恢复继续运行**

- 恢复失败

  验证点：**对流程中失败的节点，恢复失败，将从失败任务进行任务的重新提交**

- 停止

  验证点：**将正在运行的任务kill掉**

- 删除：

  验证点：**只有终态的流程实例才可以删除，删除流程实例的时候，流程实例和任务实例是级联删除的，同时如果zk中有关联的此流程实例的任务实例，将会删除**

### 任务实例

- 日志查看

  验证点：**查看运行的日志，测试大一点的日志，日志是分片查看的，上下拖动，分片请求**

## 监控中心

### 服务监控

**Master/Worker/Zookeeper/MySQL服务是否正常**

### 统计管理

- 待执行的流程数

  验证点：统计Command的个数

- 执行失败的命令数

  验证点：异常Command的个数

- 待运行任务

  验证点：ZK Queue中等待的运行任务数

- 待杀死任务数

  验证点：Zk Queue中等待Kill的任务



# 2，容错测试

**二台Master和三台Worker情况下**

- Worker掉了

  验证点：**Worker掉了，Master会感知到，然后将任务状态修改为需要容错，Master监控到任务为需要容错，对任务进行重新提交，走的是重试的逻辑**

- 多Master中的一个Master掉了

  验证点：**Master会走流程容错，其它的Master接管这个流程的监控**

- 两个Master同时掉了，Master重启

  验证点：**走Master的自容错机制，恢复流程的监控**

- 两个Master同时掉了之后，其中一个Worker掉了，在两个Master重启之前，Worker重启了

  验证点：**1，Master启动的时候走自容错恢复流程的监控**

  ​		**2，对Worker上的任务修改为需要容错（此时重要的是需要根据Master的启动时间，和Worker的时间，如果Master启动时间比Worker晚，那说明中间Worker重启过，需要容错），任务进行重新提交**

