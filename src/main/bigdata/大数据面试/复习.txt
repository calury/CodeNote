

### hadoop

1、入门
    （1）常用端口
    2.x 50070 8088 19888 9000
    3.x 9870             8020

    （2）安装hadoop的8个配置文件
    site: core-site   hdfs-site yarn-site mapred-site
    hadoop-env yarn-env mapred-env
    slaves(3.x变成works）

2、HDFS
    （1） HDFS读写流程
        读
    （2） 小文件问题
        1、 会影响
            nn的内存：
                一个文件块 占用150个字节 如果有1亿个小文件
                128G能存储多少文件块： 128G * 1024 * 1024 * 1024 / 150字节 = 9亿个文件

            分片对应一个maptask
                默认1个文件是一个切片

        2、 怎么解决
                处理方式：1.har归档（常用） + 使用自定义Inputformat sequencefile
                    2.减少切片：采用combineFileInputFormat，先聚合再切片
                    3.JVM重用（双刃剑，如果没有小文件，就不要开启）  开启后提高60%

3、 MR
    必须要了解的是：shuffle及其优化
        map方法之后，reduce方法之前，混洗的过程

        优化：
            getPartition: 自定义分区
            环形缓存区：增大存储大小，80-90%   （减少一些文件）
            一次溢写文件合并的文件大小：从10-20个 （默认一次归并是10个） 提高到多少取决于pc的性能
            提前Combine（不影响最终的业务逻辑：求和）如果求平均值就不能用
            落盘后到reduce，压缩，减少网络传输
            落盘后到reduce：一次性拉多个文件，然后reduce增加内存

        能够进行压缩的：
                    map                 reduce
            看大小：小、快 snappy lzo
            看切片：lzo，biz2

        整体优化
            NN单节点默认内存：8G -》 生产可以调到100G
            单任务默认内存
                压缩了还不支持切片，maptask就需要调大内存，默认是一个G
                18m-> 1g
                1g -> 8g


4、 YARN
    （1）工作机制

    （2）调度器
        FIFO调度器 容量调度器  公平调度器
        默认是apache 容量   CDP、HDP 公平
        3. FIFO 单队列，先进先出，基本不用
        4. 容量调度：
            支持多队列：优先满足先进来的任务的资源 不够资源可以借
        5. 公平调度
            特点：每个任务公平享有队列的资源，不够的时候，按照缺额多少分配，并发度最高

            大企业选择公平（并发要求高，服务器性能好），中小企业选择容量
        6. 用多少个队列
            按框架：hive、flink、spark
            按业务：登录、订单、支付等

            大公司还有：降级使用，比如双11的时候

### Zookeeper
    选举机制：半数机制
    安装基数台
    常用命令

### Flume
    1、组成（source channel sink 事务）
        （1）taildir source
            断点续传 多目录  apache1.7 cdh1.6
            之前的版本需要使用自定义source才能实现
            如果挂了怎么办？（数据会重复，但是不会丢失）
                自身解决：使用事务，但在企业中不用
                下游处理：dwd处理、sparkstreaming去重

        （2）channel
            file
            memory
            kafka channel: 磁盘  可靠性高    效率高于memory channel + kafka sink
                flume在1.6报表有bug，使用tipic头，1.7版本解决

        （3）HDFS sink
            小文件问题：大小（128m），时间（1-2个小时），event个数（不用）

    2、拦截器 监控器 选择器
        （1）拦截器
            ETL：判断json是否完整

    3、优化及挂了怎么办

### Kafka

### Spark
1、入门
    部署：
        local
        standalone  对效率追求比较高的场景 国内很小使用
        yarn
        mosoe
        k8s
    启动流程：

2、Sparkcore
    代码在哪执行：driver、 executor
    五大属性
        标记数据是哪个分区的
        计算
        依赖
        分区器
        移动数据不如移动计算


3、Spark sql

4、spark streaming

5、内核

6、优化+数据倾斜