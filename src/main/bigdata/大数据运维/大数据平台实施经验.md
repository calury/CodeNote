## 大数据平台实施经验

### 1.平台规划
- hadoop有数据副本机制，因此datanode节点上，系统盘做raid1、数据盘做raid0。NameNode做raid5。这样不管系统盘还是数据盘，都可以直接更换
- 计算节点DataNode依靠的是数量优势，除了存储空间足够大之外，对机器配置要求不高。但安装spark、impala的话对内存要求比较高
- NameNode对机器配置要求较高。假如有80G元数据，64G内存就有些紧张，这个时候开始使用交互内存
- 














### 【参考资料】
1. [CDH大数据平台实施经验总结](https://blog.csdn.net/jr8801/article/details/82693824)
