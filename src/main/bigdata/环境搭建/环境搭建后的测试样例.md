hadoop
```
hdfs dfs -mkdir -p /user/appuser/mapreduce/input

vim wc.txt

hdfs dfs -put wc.txt /user/appuser/mapreduce/input/
hdfs dfs -text /user/appuser/mapreduce/input/wc.txt
# 执行wordcount
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/appuser/mapreduce/input/ /user/appuser/mapreduce/output
# 查看结果
hadoop fs -cat /user/beifeng/mapreduce/wordcount/output/part-*
```

基准测试

```
# 集群写性能：向HDFS集群写10个128M的文件
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 128MB
# 集群读性能：读取HDFS集群10个128M的文件
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB
# 清除测试数据
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -clean

# 使用Sort程序评测MapReduce
## 1.使用RandomWriter来产生随机数，每个节点运行10个map任务，每个map产生大约1G大小的二进制随机数
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar randomwriter random-data
## 2. 执行Sort程序
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar sort random-data sorted-data
## 3. 验证数据是否排好序
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar testmapredsort -sortInput random-data-sortOutput sorted-data
```

#### spark
测试spark：计算pi
```
# spark2.1.1
bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.1.1.jar 100
# # spark2.4.4
bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.4.4.jar 100
```