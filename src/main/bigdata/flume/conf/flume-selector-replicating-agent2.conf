# agent2负责从avro中读取信息，然后写入hdfs
agent2.sources = r1
agent2.sinks = k1
agent2.channels = c1

# Describe/configure the source
# source端的avro是一个数据接收服务
agent2.sources.r1.type = avro
agent2.sources.r1.bind = hadoop102
agent2.sources.r1.port = 4141

# Describe the sink
agent2.sinks.k1.type = hdfs
agent2.sinks.k1.hdfs.path = hdfs://hadoop101:8020/forlearn/flume/replicating/%Y%m%d/%H
#上传文件的前缀
agent2.sinks.k1.hdfs.filePrefix = flume2-
#是否按照时间滚动文件夹
agent2.sinks.k1.hdfs.round = true
#多少时间单位创建一个新的文件夹
agent2.sinks.k1.hdfs.roundValue = 1
#重新定义时间单位
agent2.sinks.k1.hdfs.roundUnit = hour
#是否使用本地时间戳
agent2.sinks.k1.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
agent2.sinks.k1.hdfs.batchSize = 100
#设置文件类型，可支持压缩
agent2.sinks.k1.hdfs.fileType = DataStream
#多久生成一个新的文件
agent2.sinks.k1.hdfs.rollInterval = 600
#设置每个文件的滚动大小大概是128M
agent2.sinks.k1.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
agent2.sinks.k1.hdfs.rollCount = 0

# Describe the channel
agent2.channels.c1.type = memory
agent2.channels.c1.capacity = 10000
agent2.channels.c1.transactionCapacity = 1000

# Bind the source and sink to the channel
agent2.sources.r1.channels = c1
agent2.sinks.k1.channel = c1
