# agent1监控日志，将信息复制给agent2和agent3
agent1.sources = r1
agent1.sinks = k1 k2
agent1.channels = c1 c2
# 将数据流复制给所有channel
agent1.sources.r1.selector.type = replicating
# 下面这个配置可以指定可选的channel
# agent1.sources.r1.selector.optional = c2

# Describe/configure the source
agent1.sources.r1.type = exec
agent1.sources.r1.command = tail -F /data/hive/logs/hive.log
agent1.sources.r1.shell = /bin/bash -c

# Describe the sink
# sink端的avro是一个数据发送者
agent1.sinks.k1.type = avro
agent1.sinks.k1.hostname = hadoop102 
agent1.sinks.k1.port = 4141

agent1.sinks.k2.type = avro
agent1.sinks.k2.hostname = hadoop102
agent1.sinks.k2.port = 4142

# Describe the channel
agent1.channels.c1.type = memory
agent1.channels.c1.capacity = 10000
agent1.channels.c1.transactionCapacity = 1000

agent1.channels.c2.type = memory
agent1.channels.c2.capacity = 10000
agent1.channels.c2.transactionCapacity = 1000

# Bind the source and sink to the channel
agent1.sources.r1.channels = c1 c2
agent1.sinks.k1.channel = c1
agent1.sinks.k2.channel = c2
