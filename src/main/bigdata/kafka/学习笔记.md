## 学习笔记


producer：有个分区器

consumer：
一个组负责一个topic，需要消费完整的数据。
消费者个数小于分区个数：涉及分区分配的问题
消费者个数大于分区个数：会有消费者消费不到数据


bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka --list
为什么需要--zookeeper这个参数


在Kafka 0.9版本以后，系统添加了安全机制，可以通过SSL和SASL安全机制来进行身份确认。
生产者（Producer）和消费者（Consumer）必须进行身份验证，才能操作Kafka集群。


Kafka在0.9版本中，添加了一个名为Connect的模块，即连接器。可以通过REST API提交和管理Kafka集群

Kafka 0.10及以后版本中添加了机架感知功能（为了高可用，需要往不同的机架上存数据的副本）

在Kafka 0.10及以后版本中，添加了数据流特性（Stream）拥有一系列流处理功能，例如连接（JOIN）、过滤（Filter）、聚合（Aggregate）等，能够实现一个功能齐全、低延时的实时流处理

在Kafka 0.10及以后版本中，生产者（Producer）写入的每一条消息记录都加入了时间戳（Timestamp）

#### 20210902
auto.offset.reset值含义解释
- earliest
> 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
- latest
> 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
- none
> topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常

参考资料：[Kafka auto.offset.reset值详解_李双喆-CSDN博客_auto.offset.reset](https://blog.csdn.net/lishuangzhe7047/article/details/74530417)


